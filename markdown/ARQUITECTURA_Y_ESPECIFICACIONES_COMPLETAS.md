# üèóÔ∏è Arquitectura Completa y Especificaciones - MommyShops

## üìã **√çndice**
1. [Visi√≥n General del Sistema](#-visi√≥n-general-del-sistema)
2. [Arquitectura T√©cnica](#-arquitectura-t√©cnica)
3. [Stack Tecnol√≥gico](#-stack-tecnol√≥gico)
4. [Estructura del Proyecto](#-estructura-del-proyecto)
5. [Modelos de Datos](#-modelos-de-datos)
6. [Endpoints de la API](#-endpoints-de-la-api)
7. [Procesamiento de Im√°genes y OCR](#-procesamiento-de-im√°genes-y-ocr)
8. [Integraci√≥n con APIs Externas](#-integraci√≥n-con-apis-externas)
9. [Base de Datos](#-base-de-datos)
10. [Manejo de Errores](#-manejo-de-errores)
11. [Optimizaciones de Rendimiento](#-optimizaciones-de-rendimiento)
12. [Configuraci√≥n y Despliegue](#-configuraci√≥n-y-despliegue)
13. [Testing y Debugging](#-testing-y-debugging)
14. [Lineamientos de Desarrollo](#-lineamientos-de-desarrollo)
15. [Especificaciones T√©cnicas](#-especificaciones-t√©cnicas)

---

## üéØ **Visi√≥n General del Sistema**

### **Prop√≥sito**
MommyShops es un sistema de an√°lisis de ingredientes cosm√©ticos que combina **OCR avanzado**, **m√∫ltiples fuentes de datos**, y **an√°lisis de seguridad** para proporcionar recomendaciones personalizadas sobre productos cosm√©ticos.

### **Funcionalidades Principales**
- üîç **An√°lisis de im√°genes** de productos cosm√©ticos mediante OCR
- üìù **An√°lisis de texto** de listas de ingredientes
- üåê **An√°lisis de URLs** de productos en l√≠nea
- üß™ **An√°lisis de seguridad** con m√∫ltiples fuentes de datos
- ü§ñ **Integraci√≥n con LLMs** (Ollama autoservida)
- üìä **Scoring ecol√≥gico** y recomendaciones personalizadas

---

## üèõÔ∏è **Arquitectura T√©cnica**

### **Diagrama de Componentes**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ   FastAPI       ‚îÇ    ‚îÇ   Database      ‚îÇ
‚îÇ   (React/Vue)   ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Backend       ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   PostgreSQL    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   External      ‚îÇ
                    ‚îÇ   APIs          ‚îÇ
                    ‚îÇ   (FDA, EWG,    ‚îÇ
                    ‚îÇ    CIR, etc.)   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Flujo de Datos**
```
Imagen/Texto/URL ‚Üí Preprocesamiento ‚Üí OCR/Extracci√≥n ‚Üí An√°lisis ‚Üí Recomendaci√≥n
```

---

## üõ†Ô∏è **Stack Tecnol√≥gico**

### **Backend Core**
- **Framework**: FastAPI 0.104.1 (Python 3.11+)
- **Servidor**: Uvicorn 0.24.0
- **Validaci√≥n**: Pydantic v2
- **Logging**: Python logging + structlog

### **Base de Datos**
- **SGBD**: PostgreSQL
- **ORM**: SQLAlchemy 2.0.23
- **Driver**: psycopg2-binary 2.9.9
- **Migraciones**: Alembic 1.12.1

### **Procesamiento de Im√°genes**
- **OCR**: Tesseract + pytesseract 0.3.10
- **Im√°genes**: PIL/Pillow 10.1.0
- **Procesamiento**: NumPy 1.24.3 + SciPy 1.11.4
- **Visi√≥n**: scikit-image 0.21.0

### **APIs Externas**
- **Cliente HTTP**: httpx 0.25.2
- **Web Scraping**: BeautifulSoup4 4.12.2
- **Bioinform√°tica**: BioPython 1.81

### **LLMs e IA**
- **Ollama**: Modelos locales / autoservidos
- **NVIDIA**: Nemotron integration
- **MCP**: Model Context Protocol

### **Desarrollo**
- **Testing**: pytest 7.4.3 + pytest-asyncio 0.21.1
- **Formateo**: black 23.11.0
- **Linting**: flake8 6.1.0
- **Entorno**: python-dotenv 1.0.0

---

## üìÅ **Estructura del Proyecto**

```
mommyshops/
‚îú‚îÄ‚îÄ main.py                          # üöÄ Aplicaci√≥n principal FastAPI
‚îú‚îÄ‚îÄ database.py                      # üóÑÔ∏è Modelos y conexi√≥n DB
‚îú‚îÄ‚îÄ api_utils_production.py          # üåê Utilidades para APIs externas
‚îú‚îÄ‚îÄ ollama_integration.py            # ü§ñ Cliente centralizado de Ollama
‚îú‚îÄ‚îÄ ollama_enrichment.py             # üß† Enriquecimiento estructurado v√≠a Ollama
‚îú‚îÄ‚îÄ apify_enhanced_scraper.py        # üï∑Ô∏è Web scraping avanzado
‚îú‚îÄ‚îÄ requirements.txt                 # üì¶ Dependencias Python
‚îú‚îÄ‚îÄ .env                            # ‚öôÔ∏è Variables de entorno
‚îú‚îÄ‚îÄ cosmetic_ingredients_lexicon.txt # üìö Lexicon para OCR
‚îú‚îÄ‚îÄ test_ocr_debug.py               # üîß Script de diagn√≥stico
‚îú‚îÄ‚îÄ fix_dependencies.sh             # üõ†Ô∏è Script de instalaci√≥n
‚îú‚îÄ‚îÄ test_cosmetic_ocr.py            # üß™ Test espec√≠fico de OCR cosm√©tico
‚îú‚îÄ‚îÄ test_universal_cosmetic_ocr.py   # üåç Test universal de OCR
‚îú‚îÄ‚îÄ test_different_images.py         # üì∏ Test con diferentes im√°genes
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ BACKEND_ARCHITECTURE_GUIDE.md
    ‚îú‚îÄ‚îÄ OCR_AND_IMAGE_PROCESSING_GUIDE.md
    ‚îú‚îÄ‚îÄ UNIVERSAL_OCR_GUIDE.md
    ‚îú‚îÄ‚îÄ OCR_IMPROVEMENTS_SUMMARY.md
    ‚îî‚îÄ‚îÄ ARQUITECTURA_Y_ESPECIFICACIONES_COMPLETAS.md
```

---

## üìä **Modelos de Datos**

### **Request Models (Pydantic)**
```python
class AnalyzeUrlRequest(BaseModel):
    url: str = Field(..., description="URL of the product page")
    user_need: str = Field(default="general safety", description="User's skin need")

class AnalyzeTextRequest(BaseModel):
    text: str = Field(..., description="Text containing ingredient list")
    user_need: str = Field(default="general safety", description="User's skin need")

class AnalyzeImageRequest(BaseModel):
    user_need: str = Field(default="general safety", description="User's skin need")
```

### **Response Models**
```python
class IngredientAnalysisResponse(BaseModel):
    name: str
    eco_score: float
    risk_level: str
    benefits: str
    risks_detailed: str
    sources: str

class ProductAnalysisResponse(BaseModel):
    product_name: str
    ingredients_details: List[IngredientAnalysisResponse]
    avg_eco_score: float
    suitability: str
    recommendations: str
```

### **Modelo de Base de Datos**
```python
class Ingredient(Base):
    __tablename__ = "ingredients"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, unique=True, index=True)
    eco_score = Column(Float)
    risk_level = Column(String)
    benefits = Column(Text)
    risks_detailed = Column(Text)
    sources = Column(String)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
```

---

## üöÄ **Endpoints de la API**

### **Endpoints Principales**
```python
@app.get("/")
async def root():
    """Root endpoint with system information."""

@app.post("/analyze-url")
async def analyze_url(request: AnalyzeUrlRequest, db: Session = Depends(get_db)):
    """Analyze cosmetic product from URL."""

@app.post("/analyze-text")
async def analyze_text(request: AnalyzeTextRequest, db: Session = Depends(get_db)):
    """Analyze cosmetic product from text."""

@app.post("/analyze-image")
async def analyze_image(file: UploadFile = File(...), user_need: str = Form(default="general safety"), db: Session = Depends(get_db)):
    """Analyze cosmetic product from image."""
```

### **Endpoints de Utilidad**
```python
@app.get("/health")
async def health():
    """Health check for all APIs."""

@app.get("/test-fast")
async def test_fast():
    """Test endpoint for fast processing."""

@app.post("/test-ocr")
async def test_ocr(file: UploadFile = File(...)):
    """Test endpoint for OCR debugging."""

@app.get("/cache-stats")
async def cache_stats():
    """Get cache statistics."""

@app.get("/ingredients")
async def get_all_ingredients(db: Session = Depends(get_db)):
    """Get all ingredients from database."""
```

---

## üì∏ **Procesamiento de Im√°genes y OCR**

### **Pipeline de Procesamiento**
```python
async def extract_ingredients_from_image(image_data: bytes) -> List[str]:
    """Main image processing pipeline."""
    
    # 1. Validaci√≥n
    if not TESSERACT_AVAILABLE:
        return []
    
    # 2. Preprocesamiento
    image = await preprocess_image_for_ocr(image)
    
    # 3. OCR m√∫ltiple
    text = await perform_ocr_with_retries(image)
    
    # 4. Extracci√≥n de ingredientes
    ingredients = await extract_ingredients_from_text(text)
    
    return ingredients
```

### **Preprocesamiento Avanzado**
```python
async def preprocess_image_for_ocr(image: Image.Image) -> Image.Image:
    """Advanced image preprocessing for cosmetic labels."""
    
    # Conversi√≥n a escala de grises
    # An√°lisis de calidad (varianza)
    # Mejora de nitidez condicional
    # Mejora de contraste condicional
    # Binarizaci√≥n adaptativa m√∫ltiple
    # Redimensionamiento inteligente
    # Eliminaci√≥n de ruido condicional
```

### **Configuraciones OCR Optimizadas**
```python
configs = [
    '--oem 3 --psm 7 -c tessedit_create_pdf=0',  # PSM 7 optimizado
    '--oem 3 --psm 6 -c tessedit_create_pdf=0',  # PSM 6 optimizado
    '--oem 3 --psm 8'                            # PSM 8 fallback
]
```

### **Sistema Universal de Adaptaci√≥n**
- **An√°lisis autom√°tico** de caracter√≠sticas de imagen
- **Upscaling adaptativo** basado en tama√±o y densidad
- **Preprocesamiento inteligente** seg√∫n tipo de fondo
- **Configuraciones OCR optimizadas** por densidad de texto
- **Fallbacks m√∫ltiples** para casos dif√≠ciles

---

## üåê **Integraci√≥n con APIs Externas**

### **Fuentes de Datos**
1. **FDA (Food and Drug Administration)**
2. **EWG (Environmental Working Group)**
3. **CIR (Cosmetic Ingredient Review)**
4. **SCCS (Scientific Committee on Consumer Safety)**
5. **ICCR (International Cooperation on Cosmetics Regulation)**
6. **PubChem (NIH)**
7. **INCI Beauty Database / CosIng API**
8. **IARC / INVIMA**

### **Orquestaci√≥n y Cacheo**
- `api_utils_production.py` unifica la l√≥gica en wrappers reutilizables que **normalizan** el nombre del ingrediente antes de generar claves de cache.
- Cache in-memory **thread-safe** con TTL configurable, m√©tricas (`hits`, `misses`, `evictions`) y claves normalizadas para maximizar aciertos y permitir observabilidad.
- Circuit breakers y rate limiters coordinados con prioridad de riesgo (IARC ‚ûù FDA ‚ûù CIR ‚ûù SCCS ‚ûù INVIMA ‚ûù EWG ‚ûù ICCR ‚ûù INCI ‚ûù CosIng) asegurando resiliencia frente a ca√≠das parciales.
- Logging estructurado en formato JSON con contexto (`provider`, `ingredient`, `estado del circuito`) para trazabilidad en `backend.log`.

### **Cliente HTTP Optimizado**
```python
async def fetch_ingredient_data(ingredient: str, client: httpx.AsyncClient) -> Dict:
    """Fetch ingredient data from multiple external sources."""
    
    # Paralelizaci√≥n de requests
    tasks = [
        fetch_fda_data(ingredient, client),
        fetch_ewg_data(ingredient, client),
        fetch_cir_data(ingredient, client),
        fetch_sccs_data(ingredient, client),
        fetch_iccr_data(ingredient, client),
        fetch_pubchem_data(ingredient, client)
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return aggregate_results(results)
```

> **Actualizaci√≥n 2025-03**: ahora la agregaci√≥n normaliza cada ingrediente antes de disparar solicitudes, usa cach√© en memoria con TTL y fusiona fuentes sin duplicados. Los circuit breakers y rate limiters se activan por proveedor para estabilizar FDA/EWG/INVIMA.

### **Sistema de Cach√©**
```python
# Cach√© por archivo JSON
CIR_CACHE_FILE = "cir_cache.json"
EWG_CACHE_FILE = "ewg_cache.json"
SCCS_CACHE_FILE = "sccs_cache.json"
ICCR_CACHE_FILE = "iccr_cache.json"
```

- `APICache` mantiene respuestas recientes en memoria empleando claves normalizadas (`prefijo:ingrediente`), reduciendo llamadas redundantes por variantes de OCR.
- Los archivos JSON contin√∫an disponibles como respaldo para scrapers extensos, pero el runtime favorece el cach√© en memoria para baja latencia.

---

## üóÑÔ∏è **Base de Datos**

### **Conexi√≥n y Sesiones**
```python
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

@contextmanager
def managed_session(commit: bool = False):
    if SessionLocal is None:
        raise RuntimeError("Database session factory not configured")
    session = SessionLocal()
    try:
        yield session
        if commit:
            session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()
```

> **Actualizaci√≥n 2025-03**: `managed_session()` estandariza el manejo de transacciones (incluyendo commit autom√°tico opcional), mientras que el logging JSON captura contexto (`phase`, `ingredient`, `user_id`) en `backend.log`.

### **Funciones de Consulta**
```python
def get_ingredient_data(ingredient_name: str) -> Optional[Dict]:
    """Get ingredient data from local database."""
    
def get_all_ingredients() -> List[Ingredient]:
    """Get all ingredients from database."""
```

- El diccionario en memoria se construye con claves normalizadas e incluye el nombre can√≥nico junto con los metadatos de riesgo.
- Se ampli√≥ la normalizaci√≥n con mapeos Unicode (¬µ ‚ûù micro, Œ± ‚ûù alpha, √ü ‚ûù beta) y filtros de medidas (`mg`, `¬µg/L`, `ppm`, `mg per ml`) que eliminan proporciones y unidades aisladas antes de ingresar a la base.
- Nuevos alias y entradas locales (`vitamin e`, `beta carotene`) refuerzan la precisi√≥n durante la canonicalizaci√≥n y evitan colisiones por coincidencias parciales.
- Tras cada sincronizaci√≥n externa se refresca autom√°ticamente (`refresh_local_cache_from_db`) para preparar el motor de recomendaciones.

---

## ‚ö†Ô∏è **Manejo de Errores**

### **Estrategia de Fallbacks**
```python
try:
    # M√©todo principal
    result = await primary_method()
except Exception as e:
    logger.warning(f"Primary method failed: {e}")
    try:
        # M√©todo secundario
        result = await secondary_method()
    except Exception as e:
        logger.error(f"Secondary method failed: {e}")
        # M√©todo de fallback
        result = fallback_method()
```

- Los servicios cr√≠ticos env√≠an excepciones a `backend.log` con contexto (nombre del proveedor/API) para acelerar el debugging.
- Los scrapers utilizan reintentos exponenciales (`tenacity`) y circuit breakers antes de degradarse a datos locales.

### **Validaci√≥n de Datos**
```python
# Validaci√≥n de archivos
if not file.content_type.startswith('image/'):
    raise HTTPException(status_code=400, detail="File must be an image")

# Validaci√≥n de tama√±o
if len(image_data) == 0:
    raise HTTPException(status_code=400, detail="Empty image file")
```

### **Logging Estructurado**
- `database.py`, `api_utils_production.py` y `unified_data_service.py` emplean un `JSONFormatter` personalizado que serializa cada evento con `timestamp`, `level`, `logger` y `context`.
- Ejemplo (`backend.log`):
```json
{"timestamp": "2025-03-01T12:43:10", "logger": "mommyshops.api_utils", "level": "INFO", "message": "API call summary", "context": {"ingredient": "vitamin e", "successful": ["FDA", "EWG"], "failed": {}}}
```
- Los errores cr√≠ticos utilizan `logger.exception(...)` para adjuntar `stacktrace` y metadatos (`provider`, `phase`, `user_id`).

---

## ‚ö° **Optimizaciones de Rendimiento**

### **1. Procesamiento As√≠ncrono**
```python
# Paralelizaci√≥n de requests HTTP
async with httpx.AsyncClient() as client:
    tasks = [fetch_data(source, client) for source in sources]
    results = await asyncio.gather(*tasks, return_exceptions=True)
```

### **2. Timeouts Adaptativos**
```python
# Timeouts escalonados para OCR
timeout = 10.0 if i == 0 else (8.0 if i == 1 else 5.0)

# Timeout global para an√°lisis
result = await asyncio.wait_for(
    analyze_ingredients_fast_local(ingredients, user_need, db),
    timeout=15.0
)
```

### **3. Modos de Procesamiento**
```python
# Modo ultra-r√°pido para im√°genes peque√±as
if max(original_size) < 200:
    return await extract_ingredients_ultra_fast(image)

# Modo r√°pido con l√≠mite de ingredientes
if len(ingredients) > 5:
    ingredients = ingredients[:5]
```

### **4. Cache Inteligente de Ingredientes**
- `APICache` ahora es **thread-safe**, con TTL configurable y estad√≠sticas consultables v√≠a API (`get_cache_stats`).
- Las claves emplean el nombre normalizado (`proveedor:ingrediente`) para compartir resultados entre OCR, APIs y base de datos.
- Tras procesar respuestas, los datos se fusionan junto con la fuente local para evitar duplicados y acelerar el futuro motor de recomendaciones.

### **4. Cach√© Inteligente**
```python
# Verificar cach√© local primero
local_data = get_ingredient_data(ingredient)
if local_data:
    return local_data

# Cach√© de APIs externas
if ingredient in cache:
    return cache[ingredient]
```

---

## ‚öôÔ∏è **Configuraci√≥n y Despliegue**

### **Variables de Entorno**
```bash
# Database
DATABASE_URL=postgresql://postgres@localhost:5432/mommyshops_db

# OCR
TESSERACT_PATH=/opt/homebrew/bin/tesseract

# APIs
OPENAI_API_KEY=sk-proj-...
NVIDIA_API_KEY=nvapi-...
APIFY_API_KEY=apify_api_...

# External Services
ENTREZ_EMAIL=your-email@example.com
```

### **Scripts de Instalaci√≥n**
```bash
# fix_dependencies.sh
pip install -r requirements.txt
brew install tesseract
python test_ocr_debug.py
```

### **Comando de Inicio**
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

---

## üß™ **Testing y Debugging**

### **Script de Diagn√≥stico**
```python
# test_ocr_debug.py
async def main():
    tests = [
        ("Dependencies", test_dependencies),
        ("Tesseract", test_tesseract),
        ("Image Processing", test_image_processing),
        ("OCR Sample", test_ocr_with_sample),
        ("Database", test_database_connection),
        ("FastAPI", test_fastapi_endpoints),
    ]
```

### **Cobertura Actualizada (Mar 2025)**
- `test_minimal.py` incorpora casos para caracteres especiales (`Œ±`, `¬µ`, `√ü`), filtrado de medidas compuestas (`¬µg/L`, `ppm`, `mg per ml`), m√©tricas del `APICache` y recuperaci√≥n del `CircuitBreaker`.
- `test_complete_system.py` valida el pipeline de canonicalizaci√≥n asegurando salidas limpias antes del motor de recomendaciones.
- `test_firebase_integration.py` prueba el nuevo context manager `managed_session`, garantizando commits y rollbacks consistentes antes de sincronizar con Firebase.

### **Endpoints de Testing**
```python
@app.post("/test-ocr")
async def test_ocr(file: UploadFile = File(...)):
    """Test different OCR configurations."""
    
@app.get("/test-fast")
async def test_fast():
    """Test fast processing capabilities."""
```

---

## üìã **Lineamientos de Desarrollo**

### **1. Estructura de C√≥digo**
- **Separaci√≥n de responsabilidades**: Cada m√≥dulo tiene una funci√≥n espec√≠fica
- **Funciones as√≠ncronas**: Para operaciones I/O intensivas
- **Manejo de errores**: Try-catch con logging detallado
- **Validaci√≥n de datos**: Pydantic para request/response models

### **2. Convenciones de Naming**
- **Funciones**: `snake_case` descriptivo
- **Clases**: `PascalCase`
- **Constantes**: `UPPER_CASE`
- **Variables**: `snake_case` descriptivo

### **3. Documentaci√≥n**
- **Docstrings**: En todas las funciones p√∫blicas
- **Type hints**: En todas las funciones
- **Comentarios**: Para l√≥gica compleja
- **README**: Para setup y uso

### **4. Testing**
- **Unit tests**: Para funciones individuales
- **Integration tests**: Para endpoints
- **End-to-end tests**: Para flujos completos
- **Performance tests**: Para optimizaciones

### **5. Logging**
- **Niveles apropiados**: DEBUG, INFO, WARNING, ERROR
- **Informaci√≥n contextual**: Timestamps, request IDs
- **Estructura consistente**: Formato JSON para producci√≥n
- **Rotaci√≥n de logs**: Para evitar archivos grandes

---

## üîß **Especificaciones T√©cnicas**

### **Requisitos del Sistema**
- **Python**: 3.11+
- **PostgreSQL**: 13+
- **Tesseract**: 5.0+
- **RAM**: 4GB m√≠nimo, 8GB recomendado
- **CPU**: 2 cores m√≠nimo, 4 cores recomendado

### **L√≠mites de Rendimiento**
- **Im√°genes**: M√°ximo 10MB por archivo
- **OCR**: Timeout de 30 segundos m√°ximo
- **APIs externas**: Timeout de 10 segundos por request
- **Base de datos**: M√°ximo 100 conexiones concurrentes

### **M√©tricas de Calidad**
- **Precisi√≥n OCR**: 85-95% en im√°genes claras
- **Tiempo de respuesta**: < 15 segundos promedio
- **Disponibilidad**: 99.5% uptime objetivo
- **Throughput**: 100 requests/minuto

### **Seguridad**
- **Validaci√≥n de entrada**: Todos los inputs validados
- **Sanitizaci√≥n**: XSS y injection prevention
- **Rate limiting**: Protecci√≥n contra abuse
- **HTTPS**: Encriptaci√≥n en tr√°nsito
- **API keys**: Rotaci√≥n regular

### **Escalabilidad**
- **Horizontal**: M√∫ltiples instancias FastAPI
- **Vertical**: Optimizaci√≥n de recursos
- **Cach√© distribuido**: Redis para escalabilidad
- **Load balancer**: Nginx para distribuci√≥n

---

## üîÆ **Arquitectura Futura**

### **Mejoras Planificadas**
1. **Microservicios**: Separar OCR, an√°lisis, y APIs
2. **Message Queue**: Redis/RabbitMQ para procesamiento as√≠ncrono
3. **Load Balancer**: Nginx para distribuci√≥n de carga
4. **Monitoring**: Prometheus + Grafana
5. **CI/CD**: GitHub Actions para despliegue autom√°tico

### **Escalabilidad**
- **Horizontal**: M√∫ltiples instancias de FastAPI
- **Vertical**: Optimizaci√≥n de recursos por instancia
- **Cach√© distribuido**: Redis para cach√© compartido
- **Base de datos**: Read replicas para consultas

---

## üìö **Documentaci√≥n Adicional**

### **Gu√≠as T√©cnicas**
- **OCR Guide**: `OCR_AND_IMAGE_PROCESSING_GUIDE.md`
- **Universal OCR**: `UNIVERSAL_OCR_GUIDE.md`
- **Architecture**: `BACKEND_ARCHITECTURE_GUIDE.md`
- **API Documentation**: `http://localhost:8000/docs`

### **Endpoints de Monitoreo**
- **Health Check**: `http://localhost:8000/health`
- **Cache Stats**: `http://localhost:8000/cache-stats`
- **Test OCR**: `http://localhost:8000/test-ocr`

---

## üéâ **Conclusi√≥n**

El backend de MommyShops est√° dise√±ado para ser:

‚úÖ **Escalable**: Arquitectura modular y as√≠ncrona  
‚úÖ **Robusto**: Manejo de errores y fallbacks m√∫ltiples  
‚úÖ **Eficiente**: Optimizaciones de rendimiento y cach√©  
‚úÖ **Mantenible**: C√≥digo bien documentado y testeable  
‚úÖ **Extensible**: F√°cil agregar nuevas fuentes de datos  

La combinaci√≥n de **FastAPI**, **procesamiento as√≠ncrono**, **m√∫ltiples fuentes de datos**, y **OCR avanzado** proporciona una base s√≥lida para el an√°lisis profesional de ingredientes cosm√©ticos.

### **Caracter√≠sticas √önicas**
- üåç **OCR Universal**: Se adapta autom√°ticamente a cualquier tipo de imagen
- üöÄ **Procesamiento As√≠ncrono**: M√°xima eficiencia y rendimiento
- üß† **IA Integrada**: Ollama para an√°lisis avanzado
- üìä **M√∫ltiples Fuentes**: 7+ APIs externas para datos completos
- ‚ö° **Optimizado**: Timeouts adaptativos y cach√© inteligente

**El sistema est√° listo para producci√≥n y puede manejar cualquier tipo de an√°lisis de ingredientes cosm√©ticos con alta precisi√≥n y eficiencia.** üöÄ
